---
title: "Project_1"
author: "Sadik"
date: "5/29/2021"
output: html_document
---

MSDS 6372 Project 1 Description
For this project, we are going to be using a data set provided in Kaggle titled “Life Expectancy (WHO):  Statistical Analysis on factors influencing life expectancy”.  The information was collected over numerous years and, because of logistics in recording changes over time, there will be some missing data issues that the group must discuss and develop a strategy to proceed.  
Data, along with information on the variables included in the file can be found at https://www.kaggle.com/kumarajarshi/life-expectancy-who.   
There are two main objectives for Project 1.  Before providing the details to the objectives, the groups should investigate the data and make any additional logistic decisions like using all of the data or a subset, dealing with missing data ,cleaning up variable names, changing their data types, etc.  Once that is complete, I want each group to subset the data set into 2 data sets.  Suggested:  85% train, 15% test.

Objective 1: Display the ability to build regression models using the skills and discussions from Unit 1 and 2 with the purpose of identifying key relationships and interpreting those relationships.   
•	Build a model with the main goal to identify key relationships and that is highly interpretable.  Provide detailed information on summary statistics, EDA, and your model building process.
•	Provide interpretation of the regression coefficients of your final model including hypothesis testing, interpretation of regression coefficients, and confidence intervals. It’s also good to mention the Practical vs Statistical significance of the predictors.  Answer any additional questions using your model that you deem are relevant.
•	The training data set can be used for EDA and model fitting while the test set can be used to help compare models to make a final call.
Practical Consideration for Objective 1:
EDA, EDA, EDA!  It helps you on so many fronts so use it to your advantage.  When writing a concise report, you do not have to literally step out every single step of your model building process.  I know you guys are going to being iterating on things many many times.  That does not all have to be there.  You can summarize that iteration stuff in a paragraph.  
What is key in the report is that you develop a “story” of your analysis.  Keep in mind that when you are finished with your analysis.  You know how it is going to end (what the final models look like).  You can use this to your advantage when selecting what parts of the EDA and additional information to show.  For example, if you know that predictor X7 is in your final model and it is one of the stronger relationships, that is probably a good one to show and discuss in the EDA part.  You would show the reader, “Hey look at these interesting trends”, “Hey look at these that are not”, etc.  When you report your final model and you are bringing back up the predictors discussed in EDA, it helps build the confidence of the reader in what you are doing is making sense.  I will discuss presentation strategies “Dos and Donts” during our dead week (Unit 6).




Objective 2:  While your model from Objective 1 may be interpretable there may be some additional complexity that you could incorporate to your model so that it can predict better at the expense of interpretations.  The purpose of this objective is to go through a process to compare multiple models with the goal of developing a model that can predict the best and do well on future data.  
•	Use the training and test set to build at least one additional multiple linear regression model that attempts to find a model with additional complexity than the interpretable model of Objective 1.  The point here is to make sure we understand how to add complexity to a linear regression model.   Hint:  It’s not just including a model with predictors that you’ve eliminated from Objective 1.
•	I want you to use the ISLR text book below (and the google machine) and read up on one nonparametric technique to build a regression model.  I want you to select from k-nearest neighbors’ regression or regression trees. There is a chapter on trees in the ISLR book.  For information on knn regression, see Section 3.5.  It is important to know that knn can be applied to regression as well as classification problems.  Make sure your implementation in R is using the knn regression versions rather than the classification.  See me on this if you need help or reassurance.  You will use the training and test sets here to help determine the most appropriate tree or the most appropriate “k” in knn. 
•	http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf

•	At this point you should have at least 3 models, 2 linear regression models and 1 nonparameteric model.  For each of the three models, provide the primary measure of fit for comparisons:  test ASE.  You may also include additional metrics for completeness like R squared/Adjusted Rsquared, AIC, and BIC where applicable (remember these are only derived from the training set not the test set).  

Practical Consideration for Objective 2:
Part of Objective 2 is to get comfortable with figuring new things out.  As you learn about knn or regression trees, consider providing a brief description of how that model is used to make a prediction so your audience knows the basic idea.  It’s clearly different from multiple linear regression.  It doesn’t have to be technical. They are both pretty intuitive approaches and can be explained in a single paragraph.

When all we care about is predictions, don’t be afraid to try things.  Transformations, interactions, creating new variables from old variables.  Let your EDA help you in coming up with outside the box ideas.  Note:  This tip could be applied to Objective 1 as well, as long as it yielded an interpretable model.

Many students will eventually migrate to more automated packages in R like Caret for Objective 2.  These packages may have the ability to run CV on all of the models simultaneously and provide a CV press statistic for each one of the models.  If you choose to learn the caret package, you can combine the train and test sets together to fit your models, just report the CV ASE/PRESS instead of the test ASE.  

Another graph that is helpful for just getting a sense for how your predictions are behaving is to plot the predicted test set values versus the true values in a scatterplot.  The closer the data is to the 45 degree line the better and should.  Note:  You won’t be able to do this effectively with the caret approach listed above.


Additional details

NOTE: ALL ANALYSIS MUST BE DONE IN SAS OR R and all code must be placed in the appendix of your report. Python is okay for quick formatting of data and data visualization, but analysis should be in R or SAS.


Required Information and SAMPLE FORMAT

PAGE LIMIT: I do not necessarily require a page limit, but you should definitely be shooting for no more than 8 pages written for the main report (not including graphics and codes).  It of course will blow up quite larger than that due to graphics, tables, and code but good projects are clear, concise, and to the point.  You do not need to show output for every model you considered.  (You may put supporting plots/charts/tables etc. in the appendix if you want, just make sure you label and reference them appropriately.). Effective communication is critical here. 

The format of your paper (headers, sections, etc) is flexible although should contain the following information.  

1.	Introduction Required

2.	Data Description  Required

3.	Exploratory Data Analysis Required

4.	Addressing Objective 1:  Required
•	Restatement of Problem and the overall approach to solve it 


•	Model Selection 
		              Type of Selection
			Options: LASSO, RIDGE, ELASTIC NET,
			     Stepwise, Forward, Backward, 
		             	     Manual / Intuition,
			     A mix of all of the above.  	

•	Checking Assumptions 
			Residual Plots
			Influential point analysis (Cook’s D and Leverage)
	
•	Parameter Interpretation    
	       Interpretation                 
	       Confidence Intervals Not Required, but use if beneficial to the discussion.


5.	Addressing Objective 2:  Required

•	Restatement of problem and the overall objective 

•	Description of the approach for building a complex regression model.  Feature selection must be used here if only manually model fitting approaches were used in Objective 1.  

•	Brief description of how the nonparametric tool works intuitively.  Can this model overfit?  How?   

•	Comparison of model results 
			Table of test ASE and any other relevant model fitting metrics.
Discussion and insight as to what the results suggest.  Why does one fit better than the other?  Or perhaps why does it appear that all the models appear to be performing about the same?
6.	Final summary Required
•	Quick recap of Objective 1 and Objective 2 findings
•	Provide any additional details and comments on the implications of the models.  Scope of inference?  What other data would this model be good/poor to apply to?   Problems/concerns with the data or data collection? What would you do if you have more time?  What else would you collect? etc.  
7.	Appendix  Required
•	Well commented SAS/R Code.  You may send me a github link if you wish.
•	Graphics and summary tables (Can be placed in the appendix or in the written report itself.)
•	Make sure you include figure labels and reference them in the report if you are using an appendix to communicate figures.
8.	Peer Evaluations. Required. Due 1 week after project submission.
•	Please fill out the peer evaluation form
•	While only one member of the group needs to submit the project in 2DS, each member should submit the peer evaluation individually.  IMPORTANT!!!  Do not submit the peer evaluation in 2DS with the project.  There is a separate submission labeled “Project 1 Peer Review 1” in the assignments section of 2DS.  Each student should submit the evaluation there.

library(tidyverse)
library(curl)
library(class)
library(e1071)
library(caret)
library(plotly)
library(fuzzyjoin)
library(RCurl)
library(selectr)
library(tidyselect)
library(mvtnorm)
library(stringr)
library(disdat)
library(carData)
library(caret)
library(plotly)
#library(dbplyr)
library(dplyr)
library(ggthemes)
library(ggplot2)
library(GGally)
library(gridExtra)
library(psych)
library(ggpubr)
library(gridGraphics)
library(reshape2)
library(tuneGrid)
library(plyr)
library(randomForest)
library(earth)
library(corrplot)
library(Metrics)
library(readr)
library(Zelig)
library(faraway)
library(survival)
library(magrittr)
library(dbplyr)
library(sjmisc)
library(data.table)
library(kableExtra)
library(MLmetrics)
library(tidypredict)
library(PerformanceAnalytics)
library(rgl)
library(MatrixModels)
library(ModelMetrics)
library(rpart)
library(rpart.plot)
library(palmerpenguins)
library(mlbench)
library(ISLR)
library(MASS)
library(FNN)
library(tibble)



#There are two main objectives for Project 1.  Before providing the details to the objectives, the groups should investigate the data and make any additional logistic decisions like using all of the data or a subset, dealing with missing data ,cleaning up variable names, changing their data types, etc.  Once that is complete, I want each group to subset the data set into 2 data sets.  Suggested:  85% train, 15% test.


#Objective 1

##Build a model with the main goal to identify key relationships and that is highly interpretable.  Provide detailed information on summary statistics, EDA, and your model building process.

#dataFrame
LifeExpData<-Life_Expectancy_Data, stringsAsFactors = T
#View caseStudy2 data
View(LifeExpData)
#Checking the dimensions, the data has 2938 observatiosn with 22 variables
dim(LifeExpData)
#Data set features, to see the name of all variables
names(LifeExpData)
#Data structure
str(LifeExpData)

#Setting as factor Country and Status
LifeExpData$Status=as.factor(LifeExpData$Status)
LifeExpData$Country=as.factor(LifeExpData$Country)

#grouping education level and governmnet expenditure
LifeExpData=LifeExpData %>% 
  mutate(SchoolingGrouped = sjmisc::rec(Schooling, rec = "4.2:15.0=Undergarduate; 15.1:20.7=Graduate"))%>%
  mutate(Total_expenditureGrouped=sjmisc::rec("Total expenditure", rec = "0.74:3.99=Low; 4.00:14.39=High"))
  LifeExpData$Total_expenditureGrouped=as.factor(LifeExpData$Total_expenditureGrouped)
  LifeExpData$SchoolingGrouped=as.factor(LifeExpData$SchoolingGrouped)
  
#Chceking missing values and gandling missing values
pureData <- na.omit(LifeExpData)
na.fail(pureData)
#Missing values, pure data has zero missing values, good to start analysis
sum(is.na(pureData))
#Data Summary, after clearning missing values
summary(pureData)
str(pureData)
#Exporting pureData to folder
write.csv(pureData, file = "C:/Users/SADIK/OneDrive/Documents/Project1AppliedStatistics6372/MSDS_6372_AppliedStatistics_ProjectOne/pureData.csv")
#Rang of life expectancy is 44 and 89

range(pureData$"Life expectancy")
#training and test set
set.seed(1234)
trainIndex<-createDataPartition(pureData$"Life expectancy",p=.85,list=F)

training<-pureData[trainIndex,]
validate<-pureData[-trainIndex,]

#Chceking correlation and variance, LE has strong correlation with Schooling&IncomeComposition. LE has negative correlation with Adult Mortality. And weka correlation with populations and measles. Strong correlation between infant death and underfivedeath

data_num <- pureData %>% 
                             select_if(is.numeric)

ggcorr(data_num, 
       label = T, 
       label_size = 2,
       label_round = 2,
       hjust = 1,
       size = 3, 
       color = "royalblue",
       layout.exp = 5,
       low = "green3", 
       mid = "gray95", 
       high = "darkorange",
       name = "Correlation")
# status for each country developed and developing, added dplyr to avoid R confusion with plyr
#Developed    242 14.68%    , Developing  1407 85.32% 
  pureData %>% 
                 group_by(Status) %>% 
                 dplyr::summarise(count = n()) %>% 
                 mutate(percentage = paste0(round(count/sum(count)*100, 2), "%"))
                 
#Plot country
plot1 <-  ggplot(pureData, aes(x=Status, y = "Life expectancy", fill = Status)) +
                geom_boxplot() +
                scale_fill_manual(values=c("green3", "darkorange")) +
                labs(x = "Development Status", y = "Life Expectancy (Age)") +
                theme(legend.position = "none")

ggplotly(plot1)
#Creating model
life_selected <- pureData %>% 
                          select(-Country, -Year) %>% 
                          mutate("Hepatitis B" = ifelse("Hepatitis B" < 90, "<90% Covered", ">=90% Covered"),
                                 Polio = ifelse(Polio < 90, "<90% Covered", ">=90% Covered"),
                                 Diphtheria = ifelse(Diphtheria < 90, "<90% Covered", ">=90% Covered"),
                                 "Hepatitis B" = as.factor("Hepatitis B"),
                                 Polio = as.factor(Polio),
                                 Diphtheria = as.factor(Diphtheria))

str(life_selected)

LEmodel <- lm(formula = "Life expectancy" ~., data = life_selected)
summary(LEmodel)

LEmodel = lm(formula = 'Life.expectancy', data = life_selected)

life_model <- lm(formula = "Life expectancy" ~., data = life_selected)
summary(life_model)
# Spliting the data into Train and test, Suggested:  85% train, 15% test.
data1 = sort(sample(nrow(life_selected), nrow(life_selected)*.85))
train<-life_selected[data1,]
test<-life_selected[-data1,]
# Chcekng ouliner, Most of the columns have many outliers except Alcohol, BMI, Income compositionofresources. And median values will be used for the columns that have many outliers and we use mean value for the column that have not have many outliers.
par(mfrow=c(1,3))
boxplot(pureData$"Life expectancy",
        ylab = "Life Expectancy",
        main = "Boxplot of Life Expectancy")
boxplot(pureData$"Adult Mortality",
        ylab = "Adult Mortality",
        main = "Boxplot of Adult Mortality")
boxplot(pureData$Alcohol,
        ylab = "Alcohol",
        main = "Boxplot of Alcohol")
par(mfrow=c(1,3))
boxplot(pureData$"Hepatitis B",
        ylab = "Hepatitis B",
        main = "Boxplot of Hepatitis B")
boxplot(pureData$BMI,
        ylab = "BMI",
        main = "Boxplot of BMI")
boxplot(pureData$Polio,
        ylab = "Polio",
        main = "Boxplot of Polio")
par(mfrow=c(1,3))
boxplot(pureData$"Total expenditure",
        ylab = "Total Expenditure",
        main = "Boxplot of Total Expenditure")
boxplot(pureData$Diphtheria,
        ylab = "Diphteria",
        main = "Boxplot of Diphteria")
boxplot(pureData$GDP,
        ylab = "GDP",
        main = "Boxplot of GDP")
par(mfrow=c(1,3))
boxplot(pureData$Population,
        ylab = "Population",
        main = "Boxplot of Population")
boxplot(pureData$"thinness 1-19 years",
        ylab = "Thinness 1-19 years",
        main = "Boxplot of Thinness for 1-19 years old")
boxplot(pureData$"thinness 5-9 years",
        ylab = "Thinness 5-9 years",
        main = "Boxplot of Thinness for 5-9 years old")
par(mfrow=c(1,3))
boxplot(pureData$"Income composition of resources",
        ylab = "Income Composition",
        main = "Boxplot of Income Composition")
boxplot(pureData$Schooling,
        ylab = "Schooling",
        main = "Boxplot of Schooling")
#getting the median value
life_mean <- median(pureData$"Life expectancy",  na.rm = TRUE)
mortality_mean <- median(pureData$"Adult Mortality",  na.rm = TRUE)
hepatitis_mean <- median(pureData$"Hepatitis B",  na.rm = TRUE)
polio_mean <- median(pureData$Polio,  na.rm = TRUE)
diph_mean <- median(pureData$Diphtheria,  na.rm = TRUE)
exp_mean <- median(pureData$"Total expenditure",  na.rm = TRUE)
gdp_mean <- median(pureData$GDP,  na.rm = TRUE)
pop_mean <- median(pureData$Population,  na.rm = TRUE)
thin19_mean <- median(pureData$"thinness..1.19.years,  na.rm = TRUE)
thin9_mean <- median(pureData$"thinness 5-9 years",  na.rm = TRUE)
school_mean <- median(pureData$Schooling,  na.rm = TRUE)
#Replacing the missing values with median
pureData$"Life expectancy"[is.na(pureData$"Life expectancy")] <- life_mean
pureData$"Adult Mortality"[is.na(pureData$"Adult Mortality")] <- mortality_mean
pureData$"Hepatitis B"[is.na(pureData$"Hepatitis B")] <- hepatitis_mean
pureData$Polio[is.na(pureData$Polio)] <- polio_mean
pureData$Diphtheria[is.na(pureData$Diphtheria)] <- diph_mean
pureData$"Total expenditure"[is.na(pureData$"Total expenditure")] <- exp_mean
pureData$GDP[is.na(pureData$GDP)] <- gdp_mean
pureData$Population[is.na(pureData$Population)] <- pop_mean
pureData$"thinness 1-19 years"[is.na(pureData$"thinness 1-19 years")] <- thin19_mean
pureData$"thinness 5-9 years"[is.na(pureData$"thinness 5-9 years")] <- thin9_mean
pureData$Schooling[is.na(pureData$Schooling)] <- school_mean
# the mean value for the Alcohol, BMI, Income compositionofresources columns
alcohol_mean <- mean(pureData$Alcohol,  na.rm = TRUE)
bmi_mean <- mean(pureData$BMI,  na.rm = TRUE)
income_mean <- mean(pureData$"Income composition of resources",  na.rm = TRUE)
#Replaving the missing values
pureData$Alcohol[is.na(pureData$Alcohol)] <- alcohol_mean
pureData$BMI[is.na(pureData$BMI)] <- bmi_mean
pureData$"Income composition of resources"[is.na(pureData$"Income composition of resources")] <- income_mean
# preparing clean data
data.table(head(pureData, 50),
          options = list(scroller = TRUE, scrollX = T),
          style = 'bootstrap',
          class = 'table-bordered table-condensed')
#Verifying normality of target vaiable Life Expectancy, we can see from the plot that LE is not ditributed perfectly normal, its little left skewed. 
par(mfrow=c(1,2))
hist(pureData$"Life expectancy",
     main = "Life Expectance Distribution",
     xlab = "Life Expectancy(yrs)")
# using kernel density plot with a vertical indication of location of the mean
plot(density(pureData$"Life expectancy"),
     main = "Life Expectancy Distibution",
     xlab = "Life Expectancy (yrs)")
abline(v=mean(pureData$"Life expectancy"))

#EDA Univariate variables: Alchohol, Under five years old death,Percentgae expenditure,polio, prevalenceOfThinesForAge10To19
#we can see that Alchohol is not normaliy distibuted, its highly right skewed, the ouliners are not due to data error, abnoramly GDP values with some countries having high and low GDP, we cannot remove them
par(mfrow=c(2,2))
layout(matrix(c(1,1,2,3), 2, 2, byrow = F),
   widths=c(1,1), heights=c(1,1))
boxplot(pureData$Alcohol,
        main = "Alcohol consumption")        
plot(density(pureData$Alcohol),
     main = "Distribution of Alcohol consumed",
     xlab = "Alcohol(liters)")  
plot(density(pureData$Alcohol^0.5),
     main = "Distribution of Alcohol consumed",
     xlab = "Alcohol(liters)")
#Correlation test Alchohol and GDP. They are storngly correlated with CorCofficient 0.443 and P-value of 2.2e-16 
cor.test(pureData$Alcohol, pureData$GDP)

#Under five year old deaths, we can see that its highly right skewed
par(mfrow=c(2,2))
layout(matrix(c(1,1,2,3), 2, 2, byrow = F),
   widths=c(1,1), heights=c(1,1))
boxplot(pureData$"under-five deaths",
        main = "Under Five Year Old Deaths")      
plot(density(pureData$"under-five deaths"),
     main = "Distribution / 1000 Population",
     xlab = "Under Five Year Old Deaths(cnt)")  
plot(density(pureData$"under-five deaths"^0.5),
     main = "Distribution Rate / 1000 Population",
     xlab = "Under Five Year Old Deaths rate") 
#Correlation test , under five real old death and GDP are storngly correlated, with CorrValue -0.10 and pValue:4.476e-05
cor.test(pureData$"under-five deaths", pureData$GDP)
#Percentage Expenditure, not normaly distributed its highly right skewed
par(mfrow=c(1,2))
boxplot(pureData$"percentage expenditure",
        main = "Percentage expenditure")    
plot(density(pureData$"percentage expenditure"),
     main = "% Expenditure on health",
     xlab = "Percentage expenditure(%)")
#Corr test, percentageExpe and GDP are strongle correlated, wih corCofficinet value 0.959 and pvalue < 2.2e-16
cor.test(pureData$"percentage expenditure", pureData$GDP)
# Ploio, we can see that its not normally distributed, its heavly left skewed
par(mfrow=c(1,2))
boxplot(pureData$Polio,
        main = "Polio Immunization ") 
plot(density(pureData$Polio),
     main = "% Polio Immunization Coverage",
     xlab = "Polio Immunization (%)")
#Correlation test of polio and GDP. They are stronglt correlated with CorrCofficient: 0.1568 and Pvalue:1.529e-10
cor.test(pureData$Polio, pureData$GDP)
#Prevalence of Thinness for Age 10 t0 19, its not normaly distributed, its right skewed
par(mfrow=c(1,2))
boxplot(pureData$"thinness 1-19 years",
        main = "Prevalence of thinness ") 
plot(density(pureData$"thinness 1-19 years"),
     main = "% Prevalence of thinness",
     xlab = "Prevalence of thinness (%)") 
  
#Correlation test, they are significnatly correlated GDP and Thinnes 1-19 years
cor.test(pureData$"thinness 1-19 years", pureData$GDP)

#Predictor variables realtion with target variable LE: Income, Schooling,AdultMortality and poulation, poulation is to show ther are not correalted
# life expectancy vs. income composition positively correlated
plot(y = pureData$"Life expectancy",x = pureData$"Income composition of resources",main = "Life Expectancy vs. Income compositions",
     xlab = "Income composition of resources",
     ylab = "Life Expectancy",
     pch = 19,
     col = "blue")
abline(60,1,
       col = "red")
# LE VS Schooling, postivly correalted
plot(y = pureData$"Life expectancy",x = pureData$"Schooling",main = "Life Expectancy vs. Income compositions",xlab = "Schooling", ylab = "Life Expectancy", pch = 19,col = "orange") abline(60,1,col = "blue")
#LE vs Adult Morality: negativly correalted
plot(y = pureData$"Life expectancy",x = pureData$"Adult Mortality",main = "Life Expectancy vs. Adult Mortality",xlab = "Adult Mortality",ylab = "Life Expectancy",pch = 19,col = "yellow") abline(80, - 1,col = "blue")

#LE VS Population, not correalted, the blue line also shows 45 degree line tht shows they are nor correalted
plot(y = pureData$"Life expectancy",x = pureData$Population,main = "Life Expectancy vs. Population",xlab = "Population",
ylab = "Life Expectancy",pch = 19,col = "red") abline(50,1,col = "blue")
       
#Correlation Analysis: beween the target variable, LE and independet variables(predictor variable: AdultMorality, Infant death,Alchohol, Perecntage expenditure and Hepatitis B.
pairs.panels(pureData[,4:9], method = "pearson",hist.col = "green",density = TRUE,ellipses = TRUE)

#Correlation among LE and  the predictors(Measles, BMI,Underfivedeaths,Ploio and totalExpenditure)
pairs.panels(pureData[,c(4,10:14)], method = "pearson",hist.col = "green",density = TRUE,ellipses = TRUE)

#Correlation among LE and predictors(Diphtheria, HIv/AIDS,GDP, population,thinnes1-19)
pairs.panels(pureData[,c(4,15:19)], method = "pearson",hist.col = "green",density = TRUE,ellipses = TRUE)

# Correlation amon LE and predictors(thinnes5-9, Income, and schooling)
pairs.panels(pureData[,c(4,20:22)], method = "pearson",hist.col = "green",density = TRUE,  ellipses = TRUE )
#  Schober & Boer, Rules we are follwing for correaltion testing
#1 Negligible correlation = 0.00 - 0.09
#2 Weak correlation = 0.10 - 0.39
#3 Moderate correlation = 0.40 - 0.69
#4 Strong correlation = 0.70 - 0.89
#5 Very strong correlation = 0.90 - 1.00
# Conclusion form Correlaton Analysis:
#1. Le is strongly correlated to,Income, schooling and Adult Morality
#2. LE has modartae correaltion with BMI, HIV/AIDS, Diphtheria, thiness5-9, thinnes1-19, GDP and polio
#3. LE has weak correaltion to Alchohol, percenatgeEpend, to TotalEpend, Underfivedeath and infant death
#4 LE has weak correaltion to HepatitisB,Popuplations and Measles.

#Modeling
#Cheking missing values in each column, we can see there is no missing values
sapply(pureData, function(x) sum(is.na (x))) 
#Hist life expectancy
hist(pureData$"Life expectancy")
# model crated using strongle correlated and training data set, use data in sigle quote '', not double quote, ""
model11 <- lm(`Life expectancy` ~ Schooling +  `Adult Mortality` + `Income composition of resources`, data = training)
summary(model11)  
#Result of model11 summary
Call:
lm(formula = `Life expectancy` ~ Schooling + `Adult Mortality` + 
    `Income composition of resources`, data = training)

Residuals:
     Min       1Q   Median       3Q      Max 
-23.4757  -2.1943   0.4171   2.4253  12.7367 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                       53.450691   0.669391   79.85   <2e-16 ***
Schooling                          1.072993   0.069543   15.43   <2e-16 ***
`Adult Mortality`                 -0.030830   0.001056  -29.21   <2e-16 ***
`Income composition of resources` 12.709977   1.093072   11.63   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 4.406 on 1399 degrees of freedom
Multiple R-squared:  0.7493,	Adjusted R-squared:  0.7488 
F-statistic:  1394 on 3 and 1399 DF,  p-value: < 2.2e-16
#Interpretataion of the above model result will be given in PPx presentation
#prediction based on models11 obtained form EDA Analysis
model1pred <- predict(model11,newdata = pureData, type = "response") 
#model fitting using training data set
model.fit <- predict(model11, newdata = training)
#Comparing different models using TEST data set as per the requirment of project1 Assignment                  
#Backward step model, AIC 4165.28            
BackwardStepModel <- step(model11,direction = "backward")
#Prediction backward step model, response is useful to get predicted value
backwardstepPredi <- predict(BackwardStepModel, newdata = validate,type = "response")
#Interprating backward step
summary(BackwardStepModel)
#Forward step model, am using EDA model but  i can use null model too  
forwardmodel <- step(model11, direction="forward")
#Prediction Forwad model
predForwardModel <- predict(model11, newdata = validate, type = "response")
#Interprating the model
summary (forwardmodel)
#Step wise model using EDA model, using both forward and backward model
stepwisemodel <- step(model11, direction="both")
#Prediction using step wise data
predictstepwise <- predict(stepwisemodel, newdata = validate, type = "response")
#Interpretation of step wise model
summary (stepwisemodel)
#Chceking assumption of the models used, so that we can evaluate and select the best model
#Assumptions: Linearity, homogeneity of residuals variance-homoscedasticity, and independece of residuals error terms -Non-Multicolinearity and normality of the residuals Error
#Chceking normal distribution of error, we can see that they are almost noramly distributed
par(mfrow = c(3, 2)))
plot(density(BackwardStepModel$residuals))
plot(density(forwardmodel$residuals))
plot(density(stepwisemodel$residuals))
#Chceking homoscedasticity assumption, we can see that residulas from all model spraed equaly
par(mfrow = c(3, 2))
abline(h=0, col = "red")
plot(BackwardStepModel$fitted.values, BackwardStepModel$residuals)
abline(h=0, col = "red")
plot(forwardmodel$fitted.values, forwardmodel$residuals)
abline(h=0, col = "red")
plot(stepwisemodel$fitted.values, stepwisemodel$residuals)
abline(h=0, col = "red")
# Chceking models non-collinearity, we use VIF, Variable Inflation Factor, cause it validates correlation among independent variables
vif(BackwardStepModel)
vif(forwardmodel)
vif(stepwisemodel)
# Evaluating of Adjusted R squared for all model
summary(BackwardStepModel)$adj.r.squared 
summary(forwardmodel)$adj.r.squared 
summary(stepwisemodel)$adj.r.squared 
# Evaluating RMSE for all model
RMSE(y_pred = backwardstepPredi, y_true = validate$'Life expectancy')
RMSE(y_pred = predForwardModel, y_true = validate$"Life expectancy")
RMSE(y_pred = predictstepwise, y_true = validate$"Life expectancy")
RMSE(y_pred = predifullmodel, y_true = validate$"Life expectancy") # has 8.831 which higher RMSE that Stepwise method
# Full model, i used full prediction to show that it has high RMSE there step wise model is best model
allpredimodel <- lm(`Life expectancy` ~  - Country , data = validate)
summary(allpredimodel)                    
# Full model prediction 
predifullmodel <- predict(allpredimodel,newdata = validate, type = "response")

#Objective 2:
#1 Creating new model and Adding more complexity, adding more independent varaibles over model1 that are moderatly correlated
modelB<- lm(`Life expectancy` ~ Schooling +  `Adult Mortality` + `Income composition of resources` + GDP + Polio + BMI + Diphtheria, data = training)
summary(modelB)
#Adding polynomial This syntax fits a linear model, using the lm() function, in order to predict, using a fourth-degree polynomial in allows us to avoid having to write out a long formula
#The function returns a matrix whose columns are a basis of orthogonal polynomials, which essentially means that each column is a #linear orthogonal combination of the variables
model22 <-lm(`Life expectancy`∼Schooling+I(`Adult Mortality` ^2)+I(`Income composition of resources` ^3)+I(GDP ^4) ,data=training)
summary(model22)
#getting coef
coef(model22)
# Reading ISLR book and read up on one nonparametric technique to build a regression model. Using KNN regression
LifeExpDataCleaned$Status = as.numeric(LifeExpDataCleaned$Status) - 1
LifeExpDataCleaned$Country = as.numeric(LifeExpDataCleaned$Country) - 1
#To chcek the class of each column see if columns are numeric or Factor
sapply(LifeExpDataCleaned, class)
# split the data
LifeExpDataCleaned <- Life_Expectancy_Data_Cleaned
na.omit(LifeExpDataCleaned)
set.seed(123)
smp_size <- floor(0.75 * nrow(LifeExpDataCleaned))
train_ind  <- sample(seq_len(nrow(LifeExpDataCleaned)), size = smp_size)
train <- LifeExpDataCleaned[train_ind, ]
test <- LifeExpDataCleaned[-train_ind, ]

# Prediction using KNN
X_LifeExpDataCleaned = LifeExpDataCleaned[Life.expectancy]
y_LifeExpDataCleaned= LifeExpDataCleaned$Schooling,

# Creating grid test set
LE_grid <- data.frame(Life.expectancy = seq(range(LifeExpDataCleaned$Life.expectancy)[1], range(LifeExpDataCleaned$Life.expectancy)[2], by = 0.01))
# using 
knnmodel <- FNN::knn.reg(train = X_LifeExpDataCleaned, test = LE_grid, y = y_LifeExpDataCleaned, k = 1)
knnmode2 <- FNN::knn.reg(train = X_LifeExpDataCleaned, test = LE_grid, y = y_LifeExpDataCleaned, k = 5)
knnmode3 <- FNN::knn.reg(train = X_LifeExpDataCleaned, test = LE_grid, y = y_LifeExpDataCleaned, k = 10)
knnmode4 <- FNN::knn.reg(train = X_LifeExpDataCleaned, test = LE_grid, y = y_LifeExpDataCleaned, k = 50)
knnmode5 <- FNN::knn.reg(train = X_LifeExpDataCleaned, test = LE_grid, y = y_LifeExpDataCleaned, k = 100)
knnmode6 <- FNN::knn.reg(train = X_LifeExpDataCleaned, test = LE_grid, y = y_LifeExpDataCleaned, k = 500)
knnmode7 <- FNN::knn.reg(train = X_LifeExpDataCleaned, test = LE_grid, y = y_LifeExpDataCleaned, k = 600)

# using test predictors, for that i added prob = TRUE, using the above knn model
LE_pred <- knn(train = train, 
                test  = test,
                cl    = y_LifeExpDataCleaned,
                k     = 10,
                prob  = TRUE)
                
head(LE_pred, n = 50)

#Ploting the digram
par(mfrow = c(3, 2))
plot(Schooling ~ Life.expectancy, data = LifeExpDataCleaned, cex = .8, col = "dodgerblue", main = "k = 1")
lines(LE_grid$Life.expectancy, knnmode1$pred, col = "darkorange", lwd = 0.25)
plot(Schooling ~ Life.expectancy, data = LifeExpDataCleaned, cex = .8, col = "dodgerblue", main = "k = 5")
lines(LE_grid$Life.expectancy, knnmode2$pred, col = "darkorange", lwd = 0.25)
plot(Schooling ~ Life.expectancy, data = LifeExpDataCleaned, cex = .8, col = "dodgerblue", main = "k = 10")
lines(LE_grid$Life.expectancy, knnmode3$pred, col = "darkorange", lwd = 0.25)
plot(Schooling ~ Life.expectancy, data = LifeExpDataCleaned, cex = .8, col = "dodgerblue", main = "k = 50")
lines(LE_grid$Life.expectancy, knnmode4$pred, col = "darkorange", lwd = 0.25)
plot(Schooling ~ Life.expectancy, data = LifeExpDataCleaned, cex = .8, col = "dodgerblue", main = "k = 100")
lines(LE_grid$Life.expectancy, knnmode5$pred, col = "darkorange", lwd = 0.25)
plot(Schooling ~ Life.expectancy, data = LifeExpDataCleaned, cex = .8, col = "dodgerblue", main = "k = 500")
lines(LE_grid$Life.expectancy, knnmode6$pred, col = "darkorange", lwd = 0.25)
plot(Schooling ~ Life.expectancy, data = LifeExpDataCleaned, cex = .8, col = "dodgerblue", main = "k = 600")
lines(LE_grid$Life.expectancy, knnmode7$pred, col = "darkorange", lwd = 0.25)
# getting MSE and R  , MSE = [1] 3491.835  And R2
mse.knn5  <- mean((knnmode2$pred - LifeExpDataCleaned$Life.expectancy)^2)  
mse.knn5
# getting r squared, not good R squared
 r2.knn5   <- 1- mse.knn5/(var(LifeExpDataCleaned$Life.expectancy)
 r2.knn5 

# Comparing the models AIC
#model 1, Multiple R-squared:  0.8148,	Adjusted R-squared:  0.8143
model11 <- lm(`Life expectancy` ~ Schooling +  `Adult Mortality` + `Income composition of resources`, data = training)
summary(model11)
#model 2 , using four degree  Ploynomial, Multiple R-squared:  0.8148,	Adjusted R-squared:  0.8143
model22 <-lm(`Life expectancy`∼Schooling+I(`Adult Mortality` ^2)+I(`Income composition of resources` ^3)+I(GDP ^4) ,data=training)
summary(model22)
#model 3
knnmode2 <- FNN::knn.reg(train = X_LifeExpDataCleaned, test = LE_grid, y = y_LifeExpDataCleaned, k = 5
summary(knnmode2)


 
 

  
